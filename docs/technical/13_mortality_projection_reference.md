# Mortality Projection -- Technical Reference

**Module:** `backend/engine/a09_projection.py`
**Class:** `MortalityProjection`
**Dependencies:** `a08_lee_carter.LeeCarter`, `a01_life_table.LifeTable`

---

## 1. Overview

The `MortalityProjection` module takes a fitted Lee-Carter model and projects the mortality time index $k_t$ forward using a **Random Walk with Drift (RWD)**. It generates both deterministic (central) and stochastic (Monte Carlo) projections, and provides the critical **bridge method** `to_life_table()` that converts projected mortality rates into `LifeTable` objects compatible with the downstream actuarial engine (commutation functions, premiums, reserves).

**Position in the pipeline:**

```
a06_mortality_data --> a07_graduation --> a08_lee_carter --> a09_projection
                                                                |
                                                          to_life_table()
                                                                |
a01_life_table --> a02_commutation --> a03_actuarial_values --> a04_premiums --> a05_reserves
```

---

## 2. Random Walk with Drift (RWD) Model

### 2.1 Model Specification

After Lee-Carter fitting, the time index $k_t$ for $t = 1, \ldots, T$ captures the general level of mortality over the observed period. The standard approach models future $k_t$ values as a Random Walk with Drift:

$$k_{T+h} = k_T + h \cdot c + \sigma \sqrt{h} \cdot Z, \qquad Z \sim N(0,1)$$

where:

| Symbol | Name | Meaning |
|:-------|:-----|:--------|
| $k_T$ | Last observed | Final value of the fitted $k_t$ series |
| $h$ | Horizon step | Number of years ahead ($h = 1, 2, \ldots, H$) |
| $c$ | Drift | Average annual change in $k_t$ |
| $\sigma$ | Volatility | Standard deviation of the year-to-year innovations |
| $Z$ | Standard normal | Random shock |

### 2.2 Drift Estimation

The drift $c$ is estimated as the total change in $k_t$ divided by the number of intervals:

$$c = \frac{k_T - k_1}{T - 1}$$

This is equivalent to the slope of a simple linear regression of $k_t$ on $t$ when equally spaced. For populations with improving mortality (the typical case), $c < 0$, meaning $k_t$ is declining over time.

**Implementation** (`_estimate_drift_and_sigma`, line 98):

```python
drift = (kt[-1] - kt[0]) / (n - 1)
```

### 2.3 Volatility Estimation

The volatility $\sigma$ is estimated from the residuals (innovations) after removing the drift component:

$$\sigma = \text{sd}\left(\Delta k_t - c\right), \qquad \Delta k_t = k_t - k_{t-1}$$

where $\text{sd}(\cdot)$ uses the sample standard deviation (denominator $n-1$, i.e., `ddof=1`).

**Implementation** (lines 116-118):

```python
diffs = np.diff(kt)
innovations = diffs - drift
sigma = np.std(innovations, ddof=1)
```

### 2.4 Justification for RWD

The RWD assumption rests on the empirical observation that the first differences $\Delta k_t$ are approximately independently and identically distributed. This has been validated for many national mortality datasets. The model is:

- **Simple and interpretable**: two parameters ($c$, $\sigma$).
- **Standard in practice**: used by Lee and Carter (1992) and adopted by the U.S. Social Security Administration and many actuarial offices.
- **Parsimonious**: avoids overfitting relative to ARIMA(p,d,q) alternatives.

---

## 3. Deterministic (Central) Projection

The central projection is the expected path of $k_t$, obtained by setting $Z = 0$:

$$\hat{k}_{T+h} = k_T + h \cdot c$$

This is a straight line extending from the last observed $k_T$ with slope $c$.

**Implementation** (`_project_kt_central`, line 122):

```python
kt_last = self.lee_carter.kt[-1]
h = np.arange(1, self.horizon + 1)
return kt_last + h * self.drift
```

**Properties of the central projection:**
- It is the conditional expectation $E[k_{T+h} | k_T]$.
- It serves as the "best estimate" for deterministic pricing.
- For a population with negative drift, it projects declining $k_t$ (improving mortality).

---

## 4. Stochastic Projection (Monte Carlo)

### 4.1 Path Generation

Each stochastic path is generated by accumulating random innovations:

$$k_{T+h}^{(i)} = k_T + h \cdot c + \sigma \sum_{j=1}^{h} Z_j^{(i)}, \qquad Z_j^{(i)} \sim N(0,1)$$

Note: the cumulative sum $\sum_{j=1}^{h} Z_j$ has variance $h$, so the standard deviation of the random component at horizon $h$ is $\sigma\sqrt{h}$. This is the characteristic "fan shape" of random walk uncertainty.

**Implementation** (`_simulate_kt_paths`, line 133):

```python
rng = np.random.default_rng(self.random_seed)
innovations = rng.normal(0, 1, size=(self.n_simulations, self.horizon))
h = np.arange(1, self.horizon + 1)
drift_component = h * self.drift
random_component = self.sigma * np.cumsum(innovations, axis=1)
return kt_last + drift_component + random_component
```

**Output shape:** `(n_simulations, horizon)` -- each row is one simulated path.

### 4.2 Confidence Intervals

For a given age $x$ and future year $T+h$, the confidence interval on the death rate is computed by:

1. Extracting the column of simulated $k_t$ values at horizon $h$: $k_{T+h}^{(1)}, \ldots, k_{T+h}^{(N)}$.
2. Computing the corresponding death rate for each: $m_x^{(i)} = \exp(a_x + b_x \cdot k_{T+h}^{(i)})$.
3. Taking empirical quantiles of the $m_x^{(i)}$ distribution.

**Implementation** (`get_confidence_interval`, line 189):

```python
kt_sims = self.kt_simulated[:, year_idx]
rates = np.exp(ax + bx * kt_sims)
lower = float(np.quantile(rates, quantiles[0]))
upper = float(np.quantile(rates, quantiles[1]))
```

**Key property:** Confidence intervals widen with horizon because $\text{Var}(k_{T+h}) = h \cdot \sigma^2$. This is validated in `test_ci_bands_widen_with_horizon`.

---

## 5. Mortality Surface Reconstruction

Given any vector of $k_t$ values (central or simulated), the full mortality surface is reconstructed from the Lee-Carter formula:

$$m_{x,t} = \exp\left(a_x + b_x \cdot k_t\right)$$

**Implementation** (`get_projected_mx_surface`, line 171):

```python
return np.exp(ax[:, np.newaxis] + np.outer(bx, kt_values))
```

This returns a matrix of shape `(n_ages, len(kt_values))`.

For a single (age, year) query, `get_projected_mx` (line 158) uses the central projection.

---

## 6. The Bridge Method: `to_life_table()`

### 6.1 Purpose

`to_life_table()` is the critical method that connects the **empirical world** (Lee-Carter model fitted to observed mortality data) to the **theoretical actuarial engine** (commutation functions, premium calculations, reserve valuations). Without this bridge, projected mortality rates cannot flow into the pricing and reserving machinery.

### 6.2 Conversion Steps

For a given future year at horizon step $h$:

| Step | Formula | Purpose |
|:-----|:--------|:--------|
| 1 | $m_x = \exp(a_x + b_x \cdot \hat{k}_{T+h})$ | Reconstruct projected central death rates |
| 2 | $q_x = 1 - \exp(-m_x)$ | Convert from central rate to probability of death |
| 3 | $q_\omega = 1.0$ | Force terminal mortality (everyone dies at the last age) |
| 4 | $q_x = \text{clip}(q_x, 0, 1)$ | Ensure valid probability bounds |
| 5 | $l_{x+1} = l_x \cdot (1 - q_x)$, with $l_0 = \text{radix}$ | Build the survivor column |
| 6 | Return `LifeTable(ages, l_x)` | Create object for downstream use |

### 6.3 The $m_x \to q_x$ Conversion

The formula $q_x = 1 - \exp(-m_x)$ is derived under the **constant force of mortality** assumption within each year of age. If the force of mortality is constant at level $\mu_x$ over the interval $[x, x+1)$, then:

$$p_x = \exp(-\mu_x) \implies q_x = 1 - \exp(-\mu_x)$$

Since $m_x$ is the central death rate (an estimator of the force $\mu_x$ under this assumption), we substitute $\mu_x \approx m_x$.

**Approximation behavior:**

| $m_x$ | $q_x = 1 - e^{-m_x}$ | Linear approx $q_x \approx m_x$ | Error |
|:-------|:----------------------|:---------------------------------|:------|
| 0.001 | 0.0009995 | 0.001 | 0.05% |
| 0.01 | 0.00995 | 0.01 | 0.5% |
| 0.1 | 0.0952 | 0.1 | 5.0% |
| 0.3 | 0.2592 | 0.3 | 15.7% |

The exact formula matters at high ages where $m_x$ is large.

### 6.4 Implementation

```python
def to_life_table(self, year, radix=100_000, age_min=None, age_max=None):
    year_idx = np.searchsorted(self.projected_years, year)
    kt = self.kt_central[year_idx]
    mx = np.exp(ax + bx * kt)       # Step 1
    qx = 1.0 - np.exp(-mx)          # Step 2
    qx[-1] = 1.0                    # Step 3
    qx = np.clip(qx, 0.0, 1.0)     # Step 4
    lx = np.zeros(len(ages))
    lx[0] = radix
    for i in range(len(ages) - 1):  # Step 5
        lx[i + 1] = lx[i] * (1.0 - qx[i])
    return LifeTable(ages=list(ages.astype(int)), l_x_values=list(lx))
```

### 6.5 Confidence Interval LifeTables

`to_life_table_with_ci()` (line 300) produces three `LifeTable` objects:

| LifeTable | $k_t$ Used | Mortality Level | Scenario |
|:----------|:-----------|:----------------|:---------|
| Central | $\hat{k}_{T+h}$ (deterministic) | Expected | Best estimate |
| Optimistic | $k_t$ at lower quantile (e.g., 5th) | Lower mortality | Longevity risk scenario |
| Pessimistic | $k_t$ at upper quantile (e.g., 95th) | Higher mortality | Mortality risk scenario |

Note the direction: **lower $k_t$** means lower mortality (optimistic for the insured, risky for the insurer from a longevity perspective).

---

## 7. Downstream Connection

Once `to_life_table()` produces a `LifeTable`, the standard actuarial chain applies:

```
LifeTable(ages, l_x)
    |
    v
CommutationFunctions(life_table, interest_rate)
    -- D_x = v^x * l_x
    -- N_x = sum D_x (backward)
    -- C_x = v^{x+1} * d_x
    -- M_x = sum C_x (backward)
    |
    v
PremiumCalculator(comm)
    -- whole_life(SA, x) = SA * M_x / N_x
    -- term(SA, x, n) = SA * (M_x - M_{x+n}) / (N_x - N_{x+n})
    -- endowment(SA, x, n)
    |
    v
ReserveCalculator(comm)
    -- prospective(SA, x, t)
```

The `LifeTable` object produced by projection is **indistinguishable** from one loaded from a CSV. The downstream engine does not know or care about the origin of the life table.

---

## 8. Class API Reference

### Constructor

```python
MortalityProjection(
    lee_carter: LeeCarter,   # Fitted model
    horizon: int = 30,       # Years to project
    n_simulations: int = 1000,
    random_seed: int = 42,
)
```

All projections (central and stochastic) are computed immediately upon construction.

### Attributes

| Attribute | Type | Description |
|:----------|:-----|:------------|
| `lee_carter` | `LeeCarter` | The fitted model |
| `horizon` | `int` | Number of years projected |
| `n_simulations` | `int` | Number of stochastic paths |
| `drift` | `float` | Estimated annual drift of $k_t$ |
| `sigma` | `float` | Estimated volatility of $k_t$ changes |
| `projected_years` | `np.ndarray` | Array of future years |
| `kt_central` | `np.ndarray` | Central projection of $k_t$ (length = horizon) |
| `kt_simulated` | `np.ndarray` | Simulated $k_t$ paths (shape: n_simulations x horizon) |

### Methods

| Method | Parameters | Returns | Purpose |
|:-------|:-----------|:--------|:--------|
| `get_projected_mx(age, year)` | age: int, year: int | `float` | Central projected death rate at (age, year) |
| `get_projected_mx_surface(kt_values)` | kt_values: ndarray | `ndarray` (n_ages x len(kt)) | Full mortality surface for given $k_t$ vector |
| `get_confidence_interval(age, year, quantiles)` | age: int, year: int, quantiles: tuple | `(float, float)` | Lower and upper death rate bounds |
| `to_life_table(year, radix, age_min, age_max)` | year: int, radix: float, optional bounds | `LifeTable` | **Bridge** to actuarial engine |
| `to_life_table_with_ci(year, quantile_low, quantile_high, radix)` | year: int, quantiles, radix | `(LifeTable, LifeTable, LifeTable)` | Central + optimistic + pessimistic |
| `validate()` | -- | `Dict[str, bool]` | Check drift, sigma, trend, NaN |
| `summary()` | -- | `Dict` | Full summary statistics |

### Validation Checks

| Check | Expected | Meaning |
|:------|:---------|:--------|
| `drift_is_negative` | `True` | Mortality is improving |
| `sigma_positive` | `True` | Non-degenerate random walk |
| `central_extends_trend` | `True` | Last projected $k_t$ < last observed |
| `no_nan_in_central` | `True` | No numerical issues |

---

## 9. Test Coverage

**File:** `backend/tests/test_projection.py` -- 17 tests

| Test Category | Count | Key Validations |
|:--------------|------:|:----------------|
| Drift and sigma estimation | 3 | Linear $k_t$ gives exact drift and $\sigma=0$; real data gives negative drift |
| Central projection | 3 | Extends trend, correct length, correct year alignment |
| Stochastic simulation | 3 | Mean near central (LLN), CI widens with horizon, seed reproducibility |
| Bridge to LifeTable | 4 | Valid life table, terminal $q_x = 1$, correct radix, CI returns three tables |
| End-to-end integration | 2 | CommutationFunctions and PremiumCalculator work with projected tables |
| Validate and summary | 2 | All checks pass, summary has expected keys |

**File:** `backend/tests/test_integration_lee_carter.py` -- 3 tests

| Test | What It Proves |
|:-----|:---------------|
| `test_full_pipeline_produces_valid_premiums` | HMD -> Graduate -> Lee-Carter -> Project -> LifeTable -> Premium (whole life, term, endowment) |
| `test_mortality_improvement_lowers_premiums` | Far-future premiums < near-future premiums (mortality improvement effect) |
| `test_spain_pipeline_also_works` | Pipeline generalizes to different countries |

---

## 10. Limitations and Extensions

### Current Limitations

1. **Single-factor model**: Only one time index $k_t$ is projected. Multi-factor extensions (e.g., Renshaw-Haberman with cohort effects) are not implemented.
2. **No parameter uncertainty**: The drift and sigma estimates are treated as known. Bayesian or bootstrap approaches could quantify estimation uncertainty.
3. **RWD only**: No ARIMA(p,d,q) or structural time series alternatives for $k_t$.
4. **No jump modeling**: Extreme mortality events (pandemics, wars) are not explicitly modeled.

### Potential Extensions

- **Scenario analysis**: Use `to_life_table_with_ci()` with different quantiles for stress testing (relevant for CNSF capital requirements, Phase 3).
- **Multiple countries**: Compare drift rates across countries to assess convergence assumptions.
- **Mexican data validation**: Apply projection to INEGI/CONAPO data and compare with EMSSA-2009 tables.
